# Pipeline ETL - Dados P√∫blicos CNPJ

## üìä Vis√£o Geral

Este projeto implementa um pipeline ETL robusto e escal√°vel para processamento de dados p√∫blicos do CNPJ da Receita Federal do Brasil. O sistema √© capaz de processar grandes volumes de dados (~17GB descompactados) com auditoria completa e carregamento incremental.

### üèóÔ∏è Modelo de Entidade Relacionamento

![Modelo ERD](https://github.com/brunolnetto/RF_CNPJ/blob/master/images/Dados_RFB_ERD.png)

### ‚ú® Caracter√≠sticas Principais

- **ETL de Alta Performance**: Sistema async com processamento paralelo interno
- **Detec√ß√£o Robusta de Arquivos**: Sistema de 4 camadas com valida√ß√£o de conte√∫do
- **Processamento Incremental**: Suporte a carregamento por ano/m√™s espec√≠fico
- **Auditoria Completa**: Rastreamento de todas as opera√ß√µes com checksums e metadados
- **Formato Otimizado**: Convers√£o autom√°tica CSV ‚Üí Parquet para melhor performance
- **Arquitetura Dual**: Bancos separados para produ√ß√£o e auditoria
- **Sistema de Logs**: Logging estruturado em JSON com rota√ß√£o autom√°tica
- **Streaming de Dados**: Processamento de arquivos grandes sem carregar na mem√≥ria
- **Toler√¢ncia a Falhas**: Retry autom√°tico com backoff exponencial

### üîÑ Fluxo do Pipeline

1. **Download** - Baixa arquivos ZIP da fonte oficial com retry inteligente
2. **Extra√ß√£o** - Descompacta arquivos CSV com valida√ß√£o de integridade
3. **Convers√£o** - Transforma dados para formato Parquet otimizado (polars)
4. **Carregamento** - Sistema async de alta performance com upserts em batch

### üöÄ Arquitetura

- **Carregador de Arquivos Aprimorado**: Detec√ß√£o autom√°tica de formato (CSV/Parquet) com valida√ß√£o robusta
- **Processamento Ass√≠ncrono**: Processamento paralelo interno com controle de concorr√™ncia
- **Estrat√©gia de Carregamento Unificado**: Interface simplificada para todos os tipos de arquivo
- **Pool de Conex√µes**: Pool de conex√µes async para m√°xima performance
- **Eficiente em Mem√≥ria**: Streaming processing para arquivos de qualquer tamanho

## üìö Fonte de Dados

- **Dados Oficiais**: [Portal de Dados Abertos do Governo](https://dados.gov.br/dados/conjuntos-dados/cadastro-nacional-da-pessoa-juridica---cnpj)
- **Layout dos Dados**: [Metadados CNPJ - Receita Federal](https://www.gov.br/receitafederal/dados/cnpj-metadados.pdf)
- **Volume**: ~4.7GB compactado | ~17.1GB descompactado
- **Atualiza√ß√£o**: Mensal pela Receita Federal

## üõ†Ô∏è Requisitos do Sistema

### Infraestrutura
- **Python**: 3.9+ (recomendado 3.11+)
- **PostgreSQL**: 14.2+ 
- **Mem√≥ria RAM**: M√≠nimo 8GB (recomendado 16GB+)
- **Espa√ßo em Disco**: ~50GB livres para processamento

### Depend√™ncias Python
- **Gerenciador**: [uv](https://github.com/astral-sh/uv) (recomendado) ou pip
- **Principais**: asyncpg (async database), pyarrow (file processing), sqlalchemy (ORM)
- **Performance**: polars (convers√£o CSV‚ÜíParquet apenas)
- **Utilit√°rios**: rich (progress), pydantic (validation), pathlib (paths)
- **Ver**: `requirements.txt` para lista completa

### üìà Performance
- **Uso de Mem√≥ria**: ~70% de redu√ß√£o via streaming processing
- **Velocidade de Processamento**: 2-3x mais r√°pido com paralelismo ass√≠ncrono interno  
- **Detec√ß√£o de Arquivos**: Falhas pr√≥ximas de zero com valida√ß√£o de 4 camadas
- **Escalabilidade**: Processa 60M+ registros eficientemente

## üöÄ Instala√ß√£o e Configura√ß√£o

### 1. Setup do Banco de Dados
```bash
# Conecte ao PostgreSQL
sudo -u postgres psql

# Configure usu√°rio e senha
ALTER USER postgres PASSWORD 'sua_senha_aqui';

# Crie os bancos (produ√ß√£o e auditoria)
CREATE DATABASE dadosrfb;
CREATE DATABASE dadosrfb_analysis;
```

### 2. Configura√ß√£o do Ambiente
```bash
# Clone o reposit√≥rio
git clone https://github.com/brunolnetto/scrapper-rf-cnpj.git
cd scrapper-rf-cnpj

# Copie e configure o arquivo de ambiente
cp .env.template .env
# Edite o .env com suas credenciais
```

### 3. Instala√ß√£o das Depend√™ncias
```bash
# Op√ß√£o 1: Usando uv (recomendado)
pip install uv
uv pip install -r requirements.txt

# Op√ß√£o 2: Usando pip tradicional
pip install -r requirements.txt
```

### 4. Configura√ß√£o do `.env`
```env
# Ambiente
ENVIRONMENT=development

# Banco Principal
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=postgres
POSTGRES_PASSWORD=sua_senha
POSTGRES_DBNAME=dadosrfb

# Banco de Auditoria
AUDIT_DB_HOST=localhost
AUDIT_DB_PORT=5432
AUDIT_DB_USER=postgres
AUDIT_DB_PASSWORD=sua_senha
AUDIT_DB_NAME=dadosrfb_analysis

# Diret√≥rios (opcionais)
OUTPUT_PATH=data/DOWNLOAD_FILES
EXTRACT_PATH=data/EXTRACTED_FILES

# Carregamento
ETL_CHUNK_SIZE=50000
ETL_SUB_BATCH_SIZE=5000
ETL_INTERNAL_CONCURRENCY=3
ETL_ASYNC_POOL_MIN_SIZE=2
ETL_ASYNC_POOL_MAX_SIZE=10
```

### üîß Configura√ß√µes Avan√ßadas

O sistema suporta configura√ß√µes avan√ßadas para otimiza√ß√£o de performance:

- **`ETL_CHUNK_SIZE`**: Tamanho do batch principal (padr√£o: 50,000)
- **`ETL_SUB_BATCH_SIZE`**: Tamanho dos sub-batches internos (padr√£o: 5,000)  
- **`ETL_INTERNAL_CONCURRENCY`**: Paralelismo interno por arquivo (padr√£o: 3)
- **`ETL_ASYNC_POOL_*`**: Configura√ß√µes do pool de conex√µes async

### üìÅ Arquivos Suportados

O sistema detecta automaticamente o formato dos arquivos:

- **CSV**: `.csv`, `.txt`, `.dat` - com detec√ß√£o autom√°tica de delimitador
- **Parquet**: `.parquet` - com valida√ß√£o de magic bytes
- **Encoding**: Detec√ß√£o autom√°tica com fallback para encoding espec√≠fico por tabela
## ‚ñ∂Ô∏è Como Executar

### Comandos Principais (usando just)
```bash
# Executar ETL para m√™s/ano atual
just run

# Executar para per√≠odo espec√≠fico
just run-etl 2024 12

# Ver todos os comandos dispon√≠veis
just help
```

### Execu√ß√£o Manual
```bash
# ETL para per√≠odo atual
python -m src.main

# ETL para per√≠odo espec√≠fico
python -m src.main --year 2024 --month 12

# ETL com refresh completo (limpa tabelas)
python -m src.main --year 2024 --month 12 --full-refresh true

# Limpar tabelas espec√≠ficas
python -m src.main --clear-tables "empresa,estabelecimento"
```

### Comandos de Desenvolvimento
```bash
# Instalar depend√™ncias
just install

# Executar linting
just lint

# Limpar logs e cache
just clean

# Buscar no c√≥digo
just search "termo_pesquisa"
```

### ‚è±Ô∏è Tempo de Processamento
- **Dados completos**: 4-8 horas (dependendo da infraestrutura)
- **Processamento incremental**: 30min - 2h
- **Download**: 1-2 horas (dependendo da conex√£o)
- **Logs**: Dispon√≠veis em `logs/YYYY-MM-DD/HH_MM/`

## üóÉÔ∏è Estrutura das Tabelas

Para informa√ß√µes detalhadas, consulte o [layout oficial](https://www.gov.br/receitafederal/pt-br/assuntos/orientacao-tributaria/cadastros/consultas/arquivos/NOVOLAYOUTDOSDADOSABERTOSDOCNPJ.pdf).

### Tabelas Principais (com √≠ndices em `cnpj_basico`)
| Tabela | Descri√ß√£o | Registros Aprox. |
|--------|-----------|------------------|
| `empresa` | Dados cadastrais da matriz | ~60M |
| `estabelecimento` | Dados por unidade/filial (endere√ßos, telefones) | ~60M |
| `socios` | Dados dos s√≥cios das empresas | ~30M |
| `simples` | Dados de MEI e Simples Nacional | ~40M |

### Tabelas de Refer√™ncia
| Tabela | Descri√ß√£o |
|--------|-----------|
| `cnae` | C√≥digos e descri√ß√µes de atividades econ√¥micas |
| `quals` | Qualifica√ß√µes de pessoas f√≠sicas (s√≥cios, respons√°veis) |
| `natju` | Naturezas jur√≠dicas |
| `moti` | Motivos de situa√ß√£o cadastral |
| `pais` | C√≥digos de pa√≠ses |
| `munic` | C√≥digos de munic√≠pios |

### üîó Relacionamentos
- **Chave Principal**: `cnpj_basico` (8 primeiros d√≠gitos do CNPJ)
- **CNPJ Completo**: `cnpj_basico` + `cnpj_ordem` + `cnpj_dv` (em `estabelecimento`)
- **√çndices**: Otimizados para consultas por CNPJ e relacionamentos

## üìÅ Estrutura do Projeto

```
scrapper-rf-cnpj/
‚îú‚îÄ‚îÄ src/                   # C√≥digo fonte principal
‚îÇ   ‚îú‚îÄ‚îÄ main.py            # Ponto de entrada do ETL
‚îÇ   ‚îú‚îÄ‚îÄ core/              # Componentes principais do ETL
‚îÇ   ‚îú‚îÄ‚îÄ database/          # Modelos e conex√µes de banco
‚îÇ   ‚îú‚îÄ‚îÄ setup/             # Configura√ß√µes e logging
‚îÇ   ‚îî‚îÄ‚îÄ utils/             # Utilit√°rios diversos
‚îú‚îÄ‚îÄ data/                  # Dados processados
‚îÇ   ‚îú‚îÄ‚îÄ DOWNLOAD_FILES/    # Arquivos ZIP baixados
‚îÇ   ‚îú‚îÄ‚îÄ EXTRACTED_FILES/   # Arquivos CSV extra√≠dos
‚îÇ   ‚îî‚îÄ‚îÄ CONVERTED_FILES/   # Arquivos Parquet convertidos
‚îú‚îÄ‚îÄ examples/              # Exemplos de uso
‚îú‚îÄ‚îÄ lab/                   # Notebooks para an√°lise
‚îú‚îÄ‚îÄ logs/                  # Logs do sistema
‚îú‚îÄ‚îÄ justfile               # Comandos automatizados
‚îú‚îÄ‚îÄ requirements.txt       # Depend√™ncias Python
‚îî‚îÄ‚îÄ .env.template          # Template de configura√ß√£o
```

## üîß Recursos Avan√ßados

### Sistema de Auditoria
- Rastreamento completo de opera√ß√µes
- Metadados de arquivos processados
- Tempos de execu√ß√£o e logs estruturados
- Banco separado para dados de auditoria

### Otimiza√ß√µes de Performance
- Convers√£o autom√°tica para formato Parquet
- Carregamento em lotes (chunking)
- √çndices otimizados no PostgreSQL
- Processamento paralelo quando poss√≠vel

### Monitoramento
- Logs em formato JSON estruturado
- Contadores de registros processados
- M√©tricas de tempo de execu√ß√£o
- Valida√ß√£o de integridade dos dados

## üõ†Ô∏è Desenvolvimento

### Estrutura de C√≥digo
- **Configura√ß√£o Centralizada**: `src/setup/config.py`
- **Padr√£o Lazy Loading**: Conex√µes de banco sob demanda
- **Strategy Pattern**: Diferentes estrat√©gias de carregamento
- **Auditoria Integrada**: Rastreamento autom√°tico de opera√ß√µes

### Executando Testes
```bash
# Usar exemplos para valida√ß√£o
python examples/loading_example.py

# An√°lise explorat√≥ria
jupyter lab lab/main.ipynb
```

### Contribuindo
1. Fork o projeto
2. Crie uma branch para sua feature
3. Execute os testes e linting
4. Submeta um Pull Request

## üìù Exemplos de Uso

### Consultas SQL B√°sicas
```sql
-- Empresas ativas por estado
SELECT uf, COUNT(*) as total_empresas
FROM estabelecimento 
WHERE situacao_cadastral = '02'
GROUP BY uf
ORDER BY total_empresas DESC;

-- CNPJs completos com raz√£o social
SELECT 
    CONCAT(e.cnpj_basico, est.cnpj_ordem, est.cnpj_dv) as cnpj_completo,
    e.razao_social,
    est.nome_fantasia
FROM empresa e
JOIN estabelecimento est ON e.cnpj_basico = est.cnpj_basico
WHERE est.identificador_matriz_filial = '1';
```

### An√°lise de Dados
```python
import pandas as pd
from sqlalchemy import create_engine

# Conectar ao banco
engine = create_engine('postgresql://user:pass@localhost/dadosrfb')

# An√°lise por setor
df = pd.read_sql("""
    SELECT c.descricao as setor, COUNT(*) as empresas
    FROM empresa e
    JOIN estabelecimento est ON e.cnpj_basico = est.cnpj_basico
    JOIN cnae c ON est.cnae_fiscal_principal = c.codigo
    GROUP BY c.descricao
    ORDER BY empresas DESC
    LIMIT 20
""", engine)
```

## üÜò Troubleshooting

### Problemas Comuns
- **Erro de conex√£o**: Verifique credenciais no `.env`
- **Falta de espa√ßo**: Monitore diret√≥rio `data/`
- **Timeout de download**: Verifique conex√£o de internet
- **Mem√≥ria insuficiente**: Ajuste `chunk_size` na configura√ß√£o

### Logs e Debugging
- Logs detalhados em `logs/YYYY-MM-DD/HH_MM/`
- Use `just clean` para limpar caches
- Verifique status das tabelas no banco de auditoria

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo [LICENSE](LICENSE) para detalhes.

## ü§ù Contribuidores

- [Bruno Peixoto](https://github.com/brunolnetto) - Autor principal

## üìß Contato

Para d√∫vidas ou sugest√µes, abra uma [issue](https://github.com/brunolnetto/scrapper-rf-cnpj/issues) no GitHub.

---

‚≠ê **Se este projeto foi √∫til, considere dar uma estrela no reposit√≥rio!**
