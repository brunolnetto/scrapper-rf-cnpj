# CNPJ Benchmarking Suite

## Overview

This benchmarking suite compares **DuckDB** vs **Polars** for processing Brazilian Federal Revenue CNPJ data. It measures performance across ingestion, aggregation, and memory usage scenarios.

## Quick Start

### 1. Run Quick Test (Recommended)
Test with a small subset of your data:

```bash
# Quick test with 2 files
python3 -m benchmarks.quick_benchmark
```

### 2. Full Benchmark
Run comprehensive benchmarks on your entire dataset:

```bash
# Full benchmark on estabelecimento files
python3 -m benchmarks.run_benchmarks --data-dir data --pattern "*ESTABELE*"

# Benchmark with memory limit
python3 -m benchmarks.run_benchmarks --memory-limit 6GB --max-files 5

# Skip DuckDB or Polars tests
python3 -m benchmarks.run_benchmarks --skip-duckdb
python3 -m benchmarks.run_benchmarks --skip-polars
```

### 3. Analyze Results
Generate visualizations and analysis:

```bash
# Analyze results from a benchmark run
python3 -m benchmarks.analyze_results benchmark_output/benchmark_results_YYYYMMDD_HHMMSS.json
```

## What Gets Measured

### Performance Metrics
- **Duration**: Total processing time
- **Peak Memory**: Maximum RAM usage during processing
- **Memory Delta**: Net memory change
- **CPU Usage**: Average CPU utilization
- **I/O**: Disk read/write volumes
- **Compression Ratio**: Input vs output file size
- **Throughput**: Rows processed per second

### Test Scenarios

#### DuckDB Tests
1. **CSV Ingestion**: `CREATE TABLE AS SELECT * FROM read_csv_auto(...)`
2. **SQL Aggregation**: GROUP BY and COUNT operations
3. **Parquet Export**: COPY TO parquet with compression

#### Polars Tests
1. **Streaming Ingestion**: `scan_csv` with `collect(streaming=True)`
2. **Eager Ingestion**: Standard `read_csv` approach
3. **Chunked Processing**: Batch processing for memory-constrained scenarios
4. **Parquet Aggregation**: Lazy evaluation on parquet files

## Output Files

After running benchmarks, you'll get:

```
benchmark_output/
‚îú‚îÄ‚îÄ benchmark_results_YYYYMMDD_HHMMSS.json    # Raw results data
‚îú‚îÄ‚îÄ benchmark_report_YYYYMMDD_HHMMSS.md       # Human-readable report
‚îú‚îÄ‚îÄ duckdb/
‚îÇ   ‚îî‚îÄ‚îÄ duckdb_output.parquet                 # DuckDB output
‚îú‚îÄ‚îÄ polars/
‚îÇ   ‚îú‚îÄ‚îÄ polars_output_streaming.parquet       # Polars streaming output
‚îÇ   ‚îú‚îÄ‚îÄ polars_output_eager.parquet           # Polars eager output
‚îÇ   ‚îî‚îÄ‚îÄ polars_chunked_output.parquet         # Polars chunked output
‚îî‚îÄ‚îÄ analysis_output/                          # Generated by analyze_results.py
    ‚îú‚îÄ‚îÄ benchmark_visualization.png
    ‚îú‚îÄ‚îÄ performance_scatter.png
    ‚îú‚îÄ‚îÄ comparison_table.csv
    ‚îî‚îÄ‚îÄ comparison_table.html
```

## Example Results Interpretation

### Speed Winner
```
üèÜ DuckDB is 2.3x faster than Polars (streaming)
Duration: DuckDB 45.2s vs Polars 103.7s
```

### Memory Winner
```
üß† Polars uses 1.8x less memory than DuckDB
Peak Memory: Polars 3.2GB vs DuckDB 5.8GB
```

### Compression Winner
```
üì¶ Both achieve ~3.5x compression (25GB ‚Üí 7GB)
```

## Configuration Options

### Memory Limits
```bash
# Constrain DuckDB memory usage
python benchmarks/run_benchmarks.py --memory-limit 4GB

# Reduce Polars thread count (in code)
PolarsBenchmark(max_threads=4)
```

### File Selection
```bash
# Test specific file patterns
python benchmarks/run_benchmarks.py --pattern "*EMPRESA*"    # Company files
python benchmarks/run_benchmarks.py --pattern "*SOCIO*"     # Partner files
python benchmarks/run_benchmarks.py --pattern "*ESTABELE*"  # Establishment files

# Limit number of files for testing
python benchmarks/run_benchmarks.py --max-files 3
```

## Understanding Your Results

### When DuckDB Wins
- **Simple ingestion workflows**: SQL `CREATE TABLE AS SELECT` is extremely robust
- **Memory-constrained environments**: Automatic spilling to disk
- **Complex SQL operations**: Window functions, complex joins
- **Integration with PostgreSQL**: Direct COPY operations

### When Polars Wins  
- **Complex data transformations**: Rich DataFrame API
- **Streaming pipelines**: Lazy evaluation with memory control
- **Python ecosystem integration**: Native DataFrame objects
- **Custom processing logic**: UDFs and complex operations

### When to Use Hybrid Approach
Best of both worlds:
1. **DuckDB for ingestion**: Robust CSV ‚Üí Parquet conversion
2. **Polars for transformations**: Complex data cleaning and processing
3. **PostgreSQL for persistence**: Final data storage

## Troubleshooting

### No Files Found
```bash
# Check your data directory structure
ls data/EXTRACTED_FILES/*ESTABELE*

# Verify file pattern
python benchmarks/run_benchmarks.py --data-dir data/EXTRACTED_FILES --pattern "*"
```

### Memory Issues
```bash
# Reduce memory limit
python benchmarks/run_benchmarks.py --memory-limit 2GB --max-files 1

# Run only one tool at a time
python benchmarks/run_benchmarks.py --skip-polars  # DuckDB only
python benchmarks/run_benchmarks.py --skip-duckdb  # Polars only
```

### Import Errors
```bash
# Install required packages
pip install duckdb polars pandas matplotlib seaborn psutil
```

## Customization

### Add Custom Benchmarks
Extend the benchmark classes in:
- `benchmarks/duckdb_benchmark.py` - Add new DuckDB tests
- `benchmarks/polars_benchmark.py` - Add new Polars tests

### Modify Test Data
Edit `find_cnpj_files()` in `run_benchmarks.py` to change file discovery logic.

### Custom Metrics
Add new measurements to `BenchmarkResult` class in `benchmarks/utils.py`.

---

## Expected Performance Patterns

Based on your 25GB‚Üí7GB compression success, expect:

- **DuckDB**: More consistent memory usage, slower on complex transformations
- **Polars**: Higher peak memory, faster on vectorized operations
- **Both**: Similar compression ratios (~3.5x for CNPJ data)

The benchmarks will help you choose the right tool for your specific use case! üöÄ